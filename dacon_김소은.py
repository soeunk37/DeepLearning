# -*- coding: utf-8 -*-
"""DACON_김소은.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DaQtZ18p5HNCVFEr46Ag0H-7z-0I_f26

Goal - seperate Red wine and White wine!

출처 : https://dacon.io/codeshare/4221?dtype=recent

시작하기전에, train과 test을 병합하여 full_df로 만들어 진행하는 방법이 있습니다. <br>
그러나, [교육]을 위해 train과 test를 따로 보겠습니다.

# LIBRARY
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
import matplotlib
# %matplotlib inline

plt.style.use('fivethirtyeight')

"""# DATA ANALYSIS & CLEANING"""

#Load Data!
train= pd.read_csv("/Users/user/Downloads/data/train.csv")
test = pd.read_csv("/Users/user/Downloads/data/test.csv")
sample_submisson= pd.read_csv("/Users/user/Downloads/data/sample_submission.csv")

"""* index 구분자
* quality 품질
* fixed acidity 산도
* volatile acidity 휘발성산
* citric acid 시트르산
* residual sugar 잔당 : 발효 후 와인 속에 남아있는 당분
* chlorides 염화물
* free sulfur dioxide 독립 이산화황
* total sulfur dioxide 총 이산화황
* density 밀도
* pH 수소이온농도
* sulphates 황산염
* alcohol 도수
* type 종류
"""

#drop index column
train= train.drop(['index'],axis=1)
train.head(5)

train.shape, test.shape

#info 활용
train.info()
train.describe(include='all')

"""피쳐들의 스케일(단위)가 다르기 때문에 추후에'표준화' 진행합니다. 

e.g. ```density```와 ```pH```는 단위가 다르죠 :)

# EDA & VIZ
"""

# quality 변수
print(train['quality'].value_counts())
sns.countplot(x=train['quality']);
plt.title("dist. of type", fontfamily='serif',fontsize=12);

"""6등급의 와인이 가장 많이 있네요!"""

#distribution by 'quality'
numerical_columns = train.select_dtypes(exclude='object').columns.tolist()
numerical_columns.remove('quality')

def show_dist_plot(df, columns):
    for column in columns:
        f, ax = plt.subplots(1,2,figsize=(16,4))
        sns.stripplot(x=df['quality'],y=df[column], ax=ax[0],hue=df['quality'])  # stripplot, violinplot : 범주형 변수에 들어있는 각 범주별 데이터의 분포 확인
        sns.violinplot(data=df, x='quality', y=column, ax=ax[1])

show_dist_plot(train, numerical_columns)

"""모든 피쳐들의 의미를 헤아리고, 유의미한 피쳐를 찾는 것은 분석에 있어 큰 도움이 됩니다.<br>
그러나, 피쳐의 수가 50개가 넘는다면? 모든 피쳐들을 헤아리기 힘들겠죠! <br>
그래서 피쳐들이 많을 때 ```train.corr()``` 상관관계를 통해서 힌트를 얻곤 합니다.
"""

# 상관분석
plt.figure(figsize=(18,8))
corr= train.corr()
sns.heatmap(corr, annot=True, square=False, vmin=-.6, vmax=1.0);

# alcohol과 density(밀도) 음의 상관관계 높음(r=-0.69)

"""**주의! 상관관계와 인관관계는 다릅니다 **  <br>

분포에서의 관계가 있음을 알려주는 것이지, 원인과 결과의 관계는 아니라는 것! 기억해주세요 :)

관련 문서: https://ko.wikipedia.org/wiki/상관관계와_인과관계

# MODELING
"""

#Library
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression, Ridge
from sklearn.metrics import plot_roc_curve,accuracy_score, confusion_matrix, plot_confusion_matrix
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier

#Standardscaler
ss= StandardScaler()
train[numerical_columns] = ss.fit_transform(train[numerical_columns])

#factorize
train['type'] = pd.factorize(train['type'])[0]

train.head(3)

"""StandardScaler를 통해서 **표준화** 작업을 진행하였고, <br>
type을 0과 1로 변환해주었습니다. ML에서는 str은 들어가지 않으니 변환은 꼭! <br>
이외에도 encoding에는 ```pd.get_dummies()```, ```labelEncoder``` 등이 있습니다.
"""

X = train.drop(['quality'],axis=1)
y = train.quality

X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=.2, random_state=42)

"""* ```test_size : 0.2```   train과 test를 8:2로 구분한다는 의미!
* ```random_state : 42``` 같은 값으로 나오게 하기 위한 Seed 설정! 
"""

X_train.shape, X_test.shape

"""X_train과 X_test에서 type을 제외한 12개의 Feature이 있는 것을 볼 수 있습니다."""

def Model(model):
    model.fit(X_train,y_train)
    score = model.score(X_test,y_test)
    model_train_score= model.score(X_train,y_train)
    model_test_score=model.score(X_test,y_test)
    prediction = model.predict(X_test)
    cm = confusion_matrix(y_test, prediction)
    print("Testing Score\n", score)
    plot_confusion_matrix(model,X_test,y_test,cmap='OrRd')

#RandomForest
rf= RandomForestClassifier()
rf.fit(X_train,y_train)
Model(rf)

"""5~7등급을 예측하는데 실제로 그러한 것이 높은 것을 볼 수 있네요."""

#feature의 수가 동일한지 보고, train set에서 다룬 것처럼 testset에서 다루어 줍니다.
X_train.shape, test.shape

#drop index column
test= test.drop(['index'],axis=1)

#Standardscaler
ss= StandardScaler()
test[numerical_columns] = ss.fit_transform(test[numerical_columns])

#factorize
test['type'] = pd.factorize(test['type'])[0]

test.head(3)

final_pred = rf.predict(test)

#submission
sample_submisson['quality'] = final_pred
sample_submisson.to_csv("/Users/user/Downloads/data/submission.csv",index=False)

"""이상 기초적인 와인 품질 분류였습니다. 감사합니다.

---

추가)앙상블 학습

<b>정형 데이터를 다루는 데 가장 뛰어난 성과를 내는 알고리즘

> RandomForest

![](https://miro.medium.com/max/1678/1*Wf91XObaX2zwow7mMwDmGw.png)

* bootstrap sample : 복원추출로 인한 <b>증복된 샘플 추출
    
기본적으로 bootstrap sample은 훈련 세트의 크기와 같게 만듭니다.

1. RandomForestClassifier : 전체 특성 개수의 제곱근만큼의 특성 선택이 '최선의 분할' <br>
    - 그러나, 회귀모델 RandomForestRegressor은 전체 특성 사용
"""

#분류에 있어 각 피쳐에 대한 중요도 출력
rf.fit(X_train, y_train)
print(rf.feature_importances_)

"""하나의 특성에 과도하게 집중하지 않고 더 많은 특성이 훈련에 기여할 기회를 얻는다면 일반화 가능성을 높혀줍니다.

> 이외에, 엑스트라 트리 (ExtraTreesClassifier)

1. 기본적으로 100개의 결정 트리 훈련
2. 부트스트랩 샘플을 사용하지 않습니다. = 전체 훈련 세트를 사용
3. 노드 분할 시, 가장 좋은 분할을 찾는 것이 아닌, 무작위로 분할 = DecisionTreeClassifier 내 splitter = 'random' 지정
"""